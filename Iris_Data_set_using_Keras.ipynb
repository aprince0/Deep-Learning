{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iris Data set using Keras",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-0ys11cFP_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RHNn4mWFUhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = (load_iris())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFjwk-BgFljv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b90b5ce8-850e-4360-ecb4-e1813ac8bb2c"
      },
      "source": [
        "type(iris)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RltcVFBFv6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "acf44e37-92bf-4d18-903d-dde35864907e"
      },
      "source": [
        "print(iris.DESCR)\n",
        "print(iris.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euIN6Xf7F3cC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ae04c3b0-e2dc-4d19-ca73-4ba02157a9b1"
      },
      "source": [
        "iris.target_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhui1Jr7F-EL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMnH-CsVGDB_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "6307c93d-10a7-45a5-8fa4-73d13ce0462f"
      },
      "source": [
        "X=iris.data\n",
        "y = iris.target\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CZgCPnEh9EW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEdFSs3kGMAO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fdebf344-8451-4e52-e8eb-42f1046b2a36"
      },
      "source": [
        "y = to_categorical(y)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmnl1T-SGep_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a8206a8d-d485-42a8-9db7-6e9d6a8aa98d"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN31Lgo5h-8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88FSuPcLiQMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHKAdwLPjmhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7vuzuhyk3VH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#need to standardize or normalize the inout.example of normalization.Here divide by the max value\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ogMO3iqlBul",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8cc16575-2dcc-411c-8a35-685449ec4ccd"
      },
      "source": [
        "np.array([5,10,15,20])/20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.25, 0.5 , 0.75, 1.  ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQHcBQndlwAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler_object = MinMaxScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNDEjkHil6es",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler_object.fit(X_train)\n",
        "# we only  fit to train and use of test.we don't want to cheat and use for test data\n",
        "scaled_X_train = scaler_object.transform(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux72FvpnmyZG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1b860041-078b-4d9d-e0c9-7f700ba93180"
      },
      "source": [
        "scaled_X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.41176471, 0.40909091, 0.55357143, 0.5       ],\n",
              "       [0.97058824, 0.45454545, 0.98214286, 0.83333333],\n",
              "       [0.38235294, 0.45454545, 0.60714286, 0.58333333],\n",
              "       [0.23529412, 0.68181818, 0.05357143, 0.04166667],\n",
              "       [1.        , 0.36363636, 1.        , 0.79166667],\n",
              "       [0.44117647, 0.31818182, 0.53571429, 0.375     ],\n",
              "       [0.26470588, 0.63636364, 0.05357143, 0.04166667],\n",
              "       [0.20588235, 0.68181818, 0.03571429, 0.08333333],\n",
              "       [0.23529412, 0.81818182, 0.14285714, 0.125     ],\n",
              "       [0.20588235, 0.        , 0.42857143, 0.375     ],\n",
              "       [0.58823529, 0.31818182, 0.67857143, 0.70833333],\n",
              "       [0.14705882, 0.63636364, 0.14285714, 0.04166667],\n",
              "       [0.20588235, 0.45454545, 0.08928571, 0.04166667],\n",
              "       [0.23529412, 0.59090909, 0.10714286, 0.16666667],\n",
              "       [0.38235294, 0.31818182, 0.55357143, 0.5       ],\n",
              "       [0.23529412, 0.63636364, 0.07142857, 0.04166667],\n",
              "       [0.41176471, 0.45454545, 0.55357143, 0.45833333],\n",
              "       [1.        , 0.81818182, 1.        , 0.875     ],\n",
              "       [0.08823529, 0.54545455, 0.05357143, 0.04166667],\n",
              "       [0.55882353, 0.40909091, 0.57142857, 0.5       ],\n",
              "       [0.41176471, 0.22727273, 0.69642857, 0.79166667],\n",
              "       [0.35294118, 1.        , 0.05357143, 0.04166667],\n",
              "       [0.5       , 0.45454545, 0.66071429, 0.70833333],\n",
              "       [0.44117647, 0.31818182, 0.71428571, 0.75      ],\n",
              "       [0.5       , 0.09090909, 0.51785714, 0.375     ],\n",
              "       [0.32352941, 0.45454545, 0.60714286, 0.58333333],\n",
              "       [0.55882353, 0.63636364, 0.76785714, 0.91666667],\n",
              "       [0.35294118, 0.13636364, 0.51785714, 0.5       ],\n",
              "       [0.32352941, 0.86363636, 0.10714286, 0.125     ],\n",
              "       [0.20588235, 0.13636364, 0.39285714, 0.375     ],\n",
              "       [0.61764706, 0.31818182, 0.75      , 0.75      ],\n",
              "       [0.20588235, 0.59090909, 0.05357143, 0.04166667],\n",
              "       [0.20588235, 0.54545455, 0.01785714, 0.04166667],\n",
              "       [0.35294118, 0.18181818, 0.48214286, 0.41666667],\n",
              "       [0.70588235, 0.45454545, 0.69642857, 0.66666667],\n",
              "       [0.17647059, 0.5       , 0.07142857, 0.04166667],\n",
              "       [0.44117647, 0.36363636, 0.71428571, 0.95833333],\n",
              "       [0.20588235, 0.63636364, 0.07142857, 0.04166667],\n",
              "       [0.20588235, 0.68181818, 0.08928571, 0.20833333],\n",
              "       [0.47058824, 0.54545455, 0.66071429, 0.70833333],\n",
              "       [0.23529412, 0.22727273, 0.33928571, 0.41666667],\n",
              "       [0.76470588, 0.54545455, 0.82142857, 0.91666667],\n",
              "       [0.5       , 0.31818182, 0.71428571, 0.625     ],\n",
              "       [0.52941176, 0.27272727, 0.80357143, 0.54166667],\n",
              "       [1.        , 0.45454545, 0.89285714, 0.91666667],\n",
              "       [0.35294118, 0.22727273, 0.51785714, 0.5       ],\n",
              "       [0.02941176, 0.40909091, 0.05357143, 0.04166667],\n",
              "       [0.        , 0.45454545, 0.        , 0.        ],\n",
              "       [0.5       , 0.09090909, 0.69642857, 0.58333333],\n",
              "       [0.85294118, 0.54545455, 0.875     , 0.70833333],\n",
              "       [0.08823529, 0.5       , 0.07142857, 0.04166667],\n",
              "       [0.23529412, 0.68181818, 0.05357143, 0.08333333],\n",
              "       [0.02941176, 0.45454545, 0.03571429, 0.04166667],\n",
              "       [0.58823529, 0.22727273, 0.67857143, 0.58333333],\n",
              "       [0.58823529, 0.63636364, 0.80357143, 0.95833333],\n",
              "       [0.08823529, 0.63636364, 0.05357143, 0.08333333],\n",
              "       [0.73529412, 0.45454545, 0.78571429, 0.83333333],\n",
              "       [0.58823529, 0.59090909, 0.875     , 1.        ],\n",
              "       [0.11764706, 0.54545455, 0.03571429, 0.04166667],\n",
              "       [0.52941176, 0.40909091, 0.64285714, 0.54166667],\n",
              "       [0.64705882, 0.36363636, 0.625     , 0.58333333],\n",
              "       [0.55882353, 0.36363636, 0.66071429, 0.70833333],\n",
              "       [0.79411765, 0.54545455, 0.64285714, 0.54166667],\n",
              "       [0.61764706, 0.54545455, 0.75      , 0.91666667],\n",
              "       [0.23529412, 0.81818182, 0.08928571, 0.04166667],\n",
              "       [0.76470588, 0.5       , 0.76785714, 0.83333333],\n",
              "       [0.47058824, 0.45454545, 0.55357143, 0.58333333],\n",
              "       [0.64705882, 0.45454545, 0.73214286, 0.79166667],\n",
              "       [0.41176471, 0.27272727, 0.42857143, 0.375     ],\n",
              "       [0.26470588, 0.31818182, 0.5       , 0.54166667],\n",
              "       [0.52941176, 0.45454545, 0.625     , 0.54166667],\n",
              "       [0.05882353, 0.13636364, 0.03571429, 0.08333333],\n",
              "       [0.67647059, 0.40909091, 0.625     , 0.5       ],\n",
              "       [0.35294118, 0.27272727, 0.58928571, 0.45833333],\n",
              "       [0.29411765, 0.77272727, 0.07142857, 0.04166667],\n",
              "       [0.38235294, 0.45454545, 0.53571429, 0.5       ],\n",
              "       [0.88235294, 0.40909091, 0.92857143, 0.70833333],\n",
              "       [0.70588235, 0.59090909, 0.82142857, 0.83333333],\n",
              "       [0.23529412, 0.77272727, 0.07142857, 0.125     ],\n",
              "       [0.17647059, 0.18181818, 0.39285714, 0.375     ],\n",
              "       [0.70588235, 0.59090909, 0.82142857, 1.        ],\n",
              "       [0.85294118, 0.45454545, 0.83928571, 0.625     ],\n",
              "       [0.17647059, 0.72727273, 0.05357143, 0.        ],\n",
              "       [0.70588235, 0.5       , 0.80357143, 0.95833333],\n",
              "       [0.17647059, 0.45454545, 0.05357143, 0.04166667],\n",
              "       [0.76470588, 0.5       , 0.67857143, 0.58333333],\n",
              "       [0.91176471, 0.36363636, 0.89285714, 0.75      ],\n",
              "       [0.58823529, 0.40909091, 0.80357143, 0.70833333],\n",
              "       [0.41176471, 0.36363636, 0.53571429, 0.5       ],\n",
              "       [0.64705882, 0.45454545, 0.78571429, 0.70833333],\n",
              "       [0.58823529, 0.13636364, 0.58928571, 0.5       ],\n",
              "       [0.61764706, 0.40909091, 0.57142857, 0.5       ],\n",
              "       [0.38235294, 0.36363636, 0.67857143, 0.79166667],\n",
              "       [0.47058824, 0.45454545, 0.71428571, 0.70833333],\n",
              "       [0.32352941, 0.63636364, 0.10714286, 0.04166667],\n",
              "       [0.52941176, 0.36363636, 0.51785714, 0.5       ],\n",
              "       [0.17647059, 0.22727273, 0.60714286, 0.66666667],\n",
              "       [0.44117647, 0.90909091, 0.01785714, 0.04166667],\n",
              "       [0.44117647, 0.27272727, 0.51785714, 0.45833333],\n",
              "       [0.82352941, 0.45454545, 0.85714286, 0.83333333]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqlUoXWkn_wl",
        "colab_type": "text"
      },
      "source": [
        "Build model using keras\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JUEPqlZoD4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQBiBLovoVnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(8,input_dim =4,activation='relu'))\n",
        "model.add(Dense(8,input_dim =4,activation='relu'))\n",
        "model.add(Dense(3,activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZT1FK31o2ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get ouput softmax in terms of probabilities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6r77hOsp4fW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xawZ6j_bqZOW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "55d0b32d-4bc0-4daa-8c65-e8e25167979d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 8)                 40        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 27        \n",
            "=================================================================\n",
            "Total params: 139\n",
            "Trainable params: 139\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXSLSzmMqcEq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f346aa12-4e62-41d0-b80e-d9df2f3fe482"
      },
      "source": [
        "model.fit(scaled_X_train,y_train,epochs=150,verbose=2)\n",
        "#verbose is how much progress you want  to see when you  run this cell"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "4/4 - 0s - loss: 1.1631 - accuracy: 0.3100\n",
            "Epoch 2/150\n",
            "4/4 - 0s - loss: 1.1505 - accuracy: 0.3100\n",
            "Epoch 3/150\n",
            "4/4 - 0s - loss: 1.1403 - accuracy: 0.3100\n",
            "Epoch 4/150\n",
            "4/4 - 0s - loss: 1.1301 - accuracy: 0.3200\n",
            "Epoch 5/150\n",
            "4/4 - 0s - loss: 1.1216 - accuracy: 0.3200\n",
            "Epoch 6/150\n",
            "4/4 - 0s - loss: 1.1122 - accuracy: 0.3200\n",
            "Epoch 7/150\n",
            "4/4 - 0s - loss: 1.1038 - accuracy: 0.3300\n",
            "Epoch 8/150\n",
            "4/4 - 0s - loss: 1.0959 - accuracy: 0.3200\n",
            "Epoch 9/150\n",
            "4/4 - 0s - loss: 1.0891 - accuracy: 0.3800\n",
            "Epoch 10/150\n",
            "4/4 - 0s - loss: 1.0826 - accuracy: 0.4400\n",
            "Epoch 11/150\n",
            "4/4 - 0s - loss: 1.0772 - accuracy: 0.4500\n",
            "Epoch 12/150\n",
            "4/4 - 0s - loss: 1.0710 - accuracy: 0.5100\n",
            "Epoch 13/150\n",
            "4/4 - 0s - loss: 1.0654 - accuracy: 0.5800\n",
            "Epoch 14/150\n",
            "4/4 - 0s - loss: 1.0605 - accuracy: 0.6400\n",
            "Epoch 15/150\n",
            "4/4 - 0s - loss: 1.0554 - accuracy: 0.7200\n",
            "Epoch 16/150\n",
            "4/4 - 0s - loss: 1.0501 - accuracy: 0.7100\n",
            "Epoch 17/150\n",
            "4/4 - 0s - loss: 1.0460 - accuracy: 0.6300\n",
            "Epoch 18/150\n",
            "4/4 - 0s - loss: 1.0405 - accuracy: 0.4600\n",
            "Epoch 19/150\n",
            "4/4 - 0s - loss: 1.0363 - accuracy: 0.3700\n",
            "Epoch 20/150\n",
            "4/4 - 0s - loss: 1.0315 - accuracy: 0.3600\n",
            "Epoch 21/150\n",
            "4/4 - 0s - loss: 1.0276 - accuracy: 0.3400\n",
            "Epoch 22/150\n",
            "4/4 - 0s - loss: 1.0228 - accuracy: 0.3400\n",
            "Epoch 23/150\n",
            "4/4 - 0s - loss: 1.0176 - accuracy: 0.3400\n",
            "Epoch 24/150\n",
            "4/4 - 0s - loss: 1.0124 - accuracy: 0.3500\n",
            "Epoch 25/150\n",
            "4/4 - 0s - loss: 1.0071 - accuracy: 0.3500\n",
            "Epoch 26/150\n",
            "4/4 - 0s - loss: 1.0013 - accuracy: 0.3600\n",
            "Epoch 27/150\n",
            "4/4 - 0s - loss: 0.9959 - accuracy: 0.4000\n",
            "Epoch 28/150\n",
            "4/4 - 0s - loss: 0.9901 - accuracy: 0.4800\n",
            "Epoch 29/150\n",
            "4/4 - 0s - loss: 0.9850 - accuracy: 0.5900\n",
            "Epoch 30/150\n",
            "4/4 - 0s - loss: 0.9804 - accuracy: 0.6500\n",
            "Epoch 31/150\n",
            "4/4 - 0s - loss: 0.9755 - accuracy: 0.7200\n",
            "Epoch 32/150\n",
            "4/4 - 0s - loss: 0.9703 - accuracy: 0.7600\n",
            "Epoch 33/150\n",
            "4/4 - 0s - loss: 0.9651 - accuracy: 0.7900\n",
            "Epoch 34/150\n",
            "4/4 - 0s - loss: 0.9599 - accuracy: 0.8100\n",
            "Epoch 35/150\n",
            "4/4 - 0s - loss: 0.9549 - accuracy: 0.8200\n",
            "Epoch 36/150\n",
            "4/4 - 0s - loss: 0.9504 - accuracy: 0.8800\n",
            "Epoch 37/150\n",
            "4/4 - 0s - loss: 0.9452 - accuracy: 0.8900\n",
            "Epoch 38/150\n",
            "4/4 - 0s - loss: 0.9399 - accuracy: 0.8800\n",
            "Epoch 39/150\n",
            "4/4 - 0s - loss: 0.9342 - accuracy: 0.8300\n",
            "Epoch 40/150\n",
            "4/4 - 0s - loss: 0.9287 - accuracy: 0.8100\n",
            "Epoch 41/150\n",
            "4/4 - 0s - loss: 0.9233 - accuracy: 0.7900\n",
            "Epoch 42/150\n",
            "4/4 - 0s - loss: 0.9182 - accuracy: 0.7500\n",
            "Epoch 43/150\n",
            "4/4 - 0s - loss: 0.9123 - accuracy: 0.7200\n",
            "Epoch 44/150\n",
            "4/4 - 0s - loss: 0.9069 - accuracy: 0.7100\n",
            "Epoch 45/150\n",
            "4/4 - 0s - loss: 0.9013 - accuracy: 0.7100\n",
            "Epoch 46/150\n",
            "4/4 - 0s - loss: 0.8959 - accuracy: 0.6800\n",
            "Epoch 47/150\n",
            "4/4 - 0s - loss: 0.8906 - accuracy: 0.6700\n",
            "Epoch 48/150\n",
            "4/4 - 0s - loss: 0.8859 - accuracy: 0.6700\n",
            "Epoch 49/150\n",
            "4/4 - 0s - loss: 0.8801 - accuracy: 0.6700\n",
            "Epoch 50/150\n",
            "4/4 - 0s - loss: 0.8748 - accuracy: 0.6700\n",
            "Epoch 51/150\n",
            "4/4 - 0s - loss: 0.8691 - accuracy: 0.6800\n",
            "Epoch 52/150\n",
            "4/4 - 0s - loss: 0.8634 - accuracy: 0.6800\n",
            "Epoch 53/150\n",
            "4/4 - 0s - loss: 0.8578 - accuracy: 0.6900\n",
            "Epoch 54/150\n",
            "4/4 - 0s - loss: 0.8522 - accuracy: 0.7000\n",
            "Epoch 55/150\n",
            "4/4 - 0s - loss: 0.8465 - accuracy: 0.7000\n",
            "Epoch 56/150\n",
            "4/4 - 0s - loss: 0.8415 - accuracy: 0.7200\n",
            "Epoch 57/150\n",
            "4/4 - 0s - loss: 0.8356 - accuracy: 0.7400\n",
            "Epoch 58/150\n",
            "4/4 - 0s - loss: 0.8300 - accuracy: 0.7400\n",
            "Epoch 59/150\n",
            "4/4 - 0s - loss: 0.8250 - accuracy: 0.7300\n",
            "Epoch 60/150\n",
            "4/4 - 0s - loss: 0.8192 - accuracy: 0.7400\n",
            "Epoch 61/150\n",
            "4/4 - 0s - loss: 0.8138 - accuracy: 0.7400\n",
            "Epoch 62/150\n",
            "4/4 - 0s - loss: 0.8083 - accuracy: 0.7700\n",
            "Epoch 63/150\n",
            "4/4 - 0s - loss: 0.8029 - accuracy: 0.7600\n",
            "Epoch 64/150\n",
            "4/4 - 0s - loss: 0.7976 - accuracy: 0.7600\n",
            "Epoch 65/150\n",
            "4/4 - 0s - loss: 0.7916 - accuracy: 0.7600\n",
            "Epoch 66/150\n",
            "4/4 - 0s - loss: 0.7849 - accuracy: 0.7500\n",
            "Epoch 67/150\n",
            "4/4 - 0s - loss: 0.7800 - accuracy: 0.7400\n",
            "Epoch 68/150\n",
            "4/4 - 0s - loss: 0.7738 - accuracy: 0.7200\n",
            "Epoch 69/150\n",
            "4/4 - 0s - loss: 0.7687 - accuracy: 0.7100\n",
            "Epoch 70/150\n",
            "4/4 - 0s - loss: 0.7636 - accuracy: 0.7000\n",
            "Epoch 71/150\n",
            "4/4 - 0s - loss: 0.7578 - accuracy: 0.7100\n",
            "Epoch 72/150\n",
            "4/4 - 0s - loss: 0.7520 - accuracy: 0.7100\n",
            "Epoch 73/150\n",
            "4/4 - 0s - loss: 0.7459 - accuracy: 0.7200\n",
            "Epoch 74/150\n",
            "4/4 - 0s - loss: 0.7400 - accuracy: 0.7500\n",
            "Epoch 75/150\n",
            "4/4 - 0s - loss: 0.7339 - accuracy: 0.7600\n",
            "Epoch 76/150\n",
            "4/4 - 0s - loss: 0.7279 - accuracy: 0.7500\n",
            "Epoch 77/150\n",
            "4/4 - 0s - loss: 0.7226 - accuracy: 0.7500\n",
            "Epoch 78/150\n",
            "4/4 - 0s - loss: 0.7162 - accuracy: 0.7500\n",
            "Epoch 79/150\n",
            "4/4 - 0s - loss: 0.7114 - accuracy: 0.7100\n",
            "Epoch 80/150\n",
            "4/4 - 0s - loss: 0.7061 - accuracy: 0.7100\n",
            "Epoch 81/150\n",
            "4/4 - 0s - loss: 0.7005 - accuracy: 0.7100\n",
            "Epoch 82/150\n",
            "4/4 - 0s - loss: 0.6948 - accuracy: 0.7500\n",
            "Epoch 83/150\n",
            "4/4 - 0s - loss: 0.6881 - accuracy: 0.7500\n",
            "Epoch 84/150\n",
            "4/4 - 0s - loss: 0.6826 - accuracy: 0.7500\n",
            "Epoch 85/150\n",
            "4/4 - 0s - loss: 0.6781 - accuracy: 0.7400\n",
            "Epoch 86/150\n",
            "4/4 - 0s - loss: 0.6716 - accuracy: 0.7500\n",
            "Epoch 87/150\n",
            "4/4 - 0s - loss: 0.6661 - accuracy: 0.7500\n",
            "Epoch 88/150\n",
            "4/4 - 0s - loss: 0.6600 - accuracy: 0.7500\n",
            "Epoch 89/150\n",
            "4/4 - 0s - loss: 0.6535 - accuracy: 0.7500\n",
            "Epoch 90/150\n",
            "4/4 - 0s - loss: 0.6479 - accuracy: 0.7700\n",
            "Epoch 91/150\n",
            "4/4 - 0s - loss: 0.6428 - accuracy: 0.8100\n",
            "Epoch 92/150\n",
            "4/4 - 0s - loss: 0.6384 - accuracy: 0.8100\n",
            "Epoch 93/150\n",
            "4/4 - 0s - loss: 0.6330 - accuracy: 0.8200\n",
            "Epoch 94/150\n",
            "4/4 - 0s - loss: 0.6277 - accuracy: 0.8200\n",
            "Epoch 95/150\n",
            "4/4 - 0s - loss: 0.6222 - accuracy: 0.8200\n",
            "Epoch 96/150\n",
            "4/4 - 0s - loss: 0.6169 - accuracy: 0.8200\n",
            "Epoch 97/150\n",
            "4/4 - 0s - loss: 0.6121 - accuracy: 0.8400\n",
            "Epoch 98/150\n",
            "4/4 - 0s - loss: 0.6080 - accuracy: 0.8500\n",
            "Epoch 99/150\n",
            "4/4 - 0s - loss: 0.6026 - accuracy: 0.8600\n",
            "Epoch 100/150\n",
            "4/4 - 0s - loss: 0.5975 - accuracy: 0.8600\n",
            "Epoch 101/150\n",
            "4/4 - 0s - loss: 0.5927 - accuracy: 0.8500\n",
            "Epoch 102/150\n",
            "4/4 - 0s - loss: 0.5875 - accuracy: 0.8500\n",
            "Epoch 103/150\n",
            "4/4 - 0s - loss: 0.5824 - accuracy: 0.8500\n",
            "Epoch 104/150\n",
            "4/4 - 0s - loss: 0.5773 - accuracy: 0.8300\n",
            "Epoch 105/150\n",
            "4/4 - 0s - loss: 0.5727 - accuracy: 0.8200\n",
            "Epoch 106/150\n",
            "4/4 - 0s - loss: 0.5677 - accuracy: 0.8200\n",
            "Epoch 107/150\n",
            "4/4 - 0s - loss: 0.5635 - accuracy: 0.8200\n",
            "Epoch 108/150\n",
            "4/4 - 0s - loss: 0.5591 - accuracy: 0.8100\n",
            "Epoch 109/150\n",
            "4/4 - 0s - loss: 0.5552 - accuracy: 0.8200\n",
            "Epoch 110/150\n",
            "4/4 - 0s - loss: 0.5512 - accuracy: 0.8300\n",
            "Epoch 111/150\n",
            "4/4 - 0s - loss: 0.5479 - accuracy: 0.8600\n",
            "Epoch 112/150\n",
            "4/4 - 0s - loss: 0.5440 - accuracy: 0.8500\n",
            "Epoch 113/150\n",
            "4/4 - 0s - loss: 0.5399 - accuracy: 0.8300\n",
            "Epoch 114/150\n",
            "4/4 - 0s - loss: 0.5365 - accuracy: 0.8200\n",
            "Epoch 115/150\n",
            "4/4 - 0s - loss: 0.5327 - accuracy: 0.8300\n",
            "Epoch 116/150\n",
            "4/4 - 0s - loss: 0.5295 - accuracy: 0.8300\n",
            "Epoch 117/150\n",
            "4/4 - 0s - loss: 0.5255 - accuracy: 0.8200\n",
            "Epoch 118/150\n",
            "4/4 - 0s - loss: 0.5224 - accuracy: 0.8100\n",
            "Epoch 119/150\n",
            "4/4 - 0s - loss: 0.5190 - accuracy: 0.8200\n",
            "Epoch 120/150\n",
            "4/4 - 0s - loss: 0.5158 - accuracy: 0.7900\n",
            "Epoch 121/150\n",
            "4/4 - 0s - loss: 0.5131 - accuracy: 0.7700\n",
            "Epoch 122/150\n",
            "4/4 - 0s - loss: 0.5098 - accuracy: 0.7700\n",
            "Epoch 123/150\n",
            "4/4 - 0s - loss: 0.5066 - accuracy: 0.7800\n",
            "Epoch 124/150\n",
            "4/4 - 0s - loss: 0.5035 - accuracy: 0.7800\n",
            "Epoch 125/150\n",
            "4/4 - 0s - loss: 0.5014 - accuracy: 0.7700\n",
            "Epoch 126/150\n",
            "4/4 - 0s - loss: 0.4988 - accuracy: 0.7700\n",
            "Epoch 127/150\n",
            "4/4 - 0s - loss: 0.4957 - accuracy: 0.7700\n",
            "Epoch 128/150\n",
            "4/4 - 0s - loss: 0.4928 - accuracy: 0.8000\n",
            "Epoch 129/150\n",
            "4/4 - 0s - loss: 0.4891 - accuracy: 0.8200\n",
            "Epoch 130/150\n",
            "4/4 - 0s - loss: 0.4869 - accuracy: 0.8300\n",
            "Epoch 131/150\n",
            "4/4 - 0s - loss: 0.4834 - accuracy: 0.8300\n",
            "Epoch 132/150\n",
            "4/4 - 0s - loss: 0.4806 - accuracy: 0.8400\n",
            "Epoch 133/150\n",
            "4/4 - 0s - loss: 0.4790 - accuracy: 0.8300\n",
            "Epoch 134/150\n",
            "4/4 - 0s - loss: 0.4761 - accuracy: 0.8300\n",
            "Epoch 135/150\n",
            "4/4 - 0s - loss: 0.4729 - accuracy: 0.8400\n",
            "Epoch 136/150\n",
            "4/4 - 0s - loss: 0.4706 - accuracy: 0.8400\n",
            "Epoch 137/150\n",
            "4/4 - 0s - loss: 0.4678 - accuracy: 0.8700\n",
            "Epoch 138/150\n",
            "4/4 - 0s - loss: 0.4659 - accuracy: 0.9100\n",
            "Epoch 139/150\n",
            "4/4 - 0s - loss: 0.4678 - accuracy: 0.9300\n",
            "Epoch 140/150\n",
            "4/4 - 0s - loss: 0.4651 - accuracy: 0.9300\n",
            "Epoch 141/150\n",
            "4/4 - 0s - loss: 0.4616 - accuracy: 0.9300\n",
            "Epoch 142/150\n",
            "4/4 - 0s - loss: 0.4588 - accuracy: 0.9200\n",
            "Epoch 143/150\n",
            "4/4 - 0s - loss: 0.4563 - accuracy: 0.9200\n",
            "Epoch 144/150\n",
            "4/4 - 0s - loss: 0.4537 - accuracy: 0.9200\n",
            "Epoch 145/150\n",
            "4/4 - 0s - loss: 0.4504 - accuracy: 0.9000\n",
            "Epoch 146/150\n",
            "4/4 - 0s - loss: 0.4480 - accuracy: 0.8700\n",
            "Epoch 147/150\n",
            "4/4 - 0s - loss: 0.4463 - accuracy: 0.8600\n",
            "Epoch 148/150\n",
            "4/4 - 0s - loss: 0.4444 - accuracy: 0.8600\n",
            "Epoch 149/150\n",
            "4/4 - 0s - loss: 0.4415 - accuracy: 0.8900\n",
            "Epoch 150/150\n",
            "4/4 - 0s - loss: 0.4400 - accuracy: 0.8900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0a976f7c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKgdIB4rTkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scale test data as well, because our model is trauined on the scale model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWJ7NQmDtRI0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "outputId": "b2a3fc35-8d35-44f8-cd15-b283b3818dad"
      },
      "source": [
        "scaled_X_test = scaler_object.transform(X_test)\n",
        "model.predict(scaled_X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02841837, 0.5483821 , 0.42319945],\n",
              "       [0.9418348 , 0.02772119, 0.03044411],\n",
              "       [0.00266753, 0.35550052, 0.641832  ],\n",
              "       [0.03859771, 0.5017744 , 0.45962796],\n",
              "       [0.01617172, 0.47360125, 0.5102271 ],\n",
              "       [0.89735353, 0.05286838, 0.04977811],\n",
              "       [0.10820996, 0.51593643, 0.37585366],\n",
              "       [0.01429078, 0.3202379 , 0.6654713 ],\n",
              "       [0.01894772, 0.52769715, 0.45335516],\n",
              "       [0.0570562 , 0.55952716, 0.38341665],\n",
              "       [0.0222002 , 0.38598713, 0.5918127 ],\n",
              "       [0.84514093, 0.08593891, 0.06892011],\n",
              "       [0.93410826, 0.03132014, 0.03457166],\n",
              "       [0.8622885 , 0.07559261, 0.06211895],\n",
              "       [0.9505525 , 0.02162061, 0.02782675],\n",
              "       [0.04130732, 0.45219085, 0.50650185],\n",
              "       [0.01020369, 0.35811225, 0.63168406],\n",
              "       [0.05316206, 0.5929285 , 0.35390937],\n",
              "       [0.04289652, 0.55274975, 0.40435374],\n",
              "       [0.01147481, 0.37914884, 0.6093764 ],\n",
              "       [0.8687359 , 0.07052428, 0.06073983],\n",
              "       [0.02873394, 0.4468693 , 0.5243967 ],\n",
              "       [0.8934704 , 0.05460986, 0.05191967],\n",
              "       [0.01133466, 0.3917893 , 0.596876  ],\n",
              "       [0.00523954, 0.28508815, 0.7096723 ],\n",
              "       [0.01385003, 0.33369353, 0.65245646],\n",
              "       [0.00782737, 0.4564959 , 0.5356768 ],\n",
              "       [0.00909747, 0.32067803, 0.6702245 ],\n",
              "       [0.83445305, 0.09154436, 0.07400262],\n",
              "       [0.8445528 , 0.08672005, 0.06872714],\n",
              "       [0.9362964 , 0.02789413, 0.03580948],\n",
              "       [0.98208743, 0.00627452, 0.01163805],\n",
              "       [0.03791993, 0.45012563, 0.5119544 ],\n",
              "       [0.9032571 , 0.04906923, 0.04767374],\n",
              "       [0.87296784, 0.06500907, 0.06202306],\n",
              "       [0.01548527, 0.4452826 , 0.53923213],\n",
              "       [0.04387644, 0.45655155, 0.49957204],\n",
              "       [0.92481273, 0.03671701, 0.03847028],\n",
              "       [0.9357113 , 0.0296838 , 0.03460485],\n",
              "       [0.9701066 , 0.01190057, 0.0179928 ],\n",
              "       [0.02222058, 0.45837814, 0.51940125],\n",
              "       [0.07194089, 0.44638947, 0.48166975],\n",
              "       [0.02514938, 0.4552799 , 0.51957077],\n",
              "       [0.9624515 , 0.01523583, 0.02231256],\n",
              "       [0.9462018 , 0.02471866, 0.02907951],\n",
              "       [0.05931839, 0.6126653 , 0.32801634],\n",
              "       [0.01798115, 0.48874956, 0.49326926],\n",
              "       [0.01621485, 0.42534825, 0.55843693],\n",
              "       [0.03257151, 0.47355753, 0.49387097],\n",
              "       [0.0082683 , 0.26285696, 0.72887474]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymdrfq_Wta4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to have output in terms of classes\n",
        "predictions = model.predict_classes(scaled_X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdF5pc1yuXZ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "42e20817-52eb-4d29-fa34-f76e00173d2f"
      },
      "source": [
        "y_test.argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
              "       0, 1, 2, 2, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI36_tMWvJaD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "91461340-b7b8-431b-f242-fe1f579e291f"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
        "confusion_matrix(y_test.argmax(axis=1),predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19,  0,  0],\n",
              "       [ 0,  8,  7],\n",
              "       [ 0,  0, 16]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rku3vfTnvkFP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "d5407ece-ba70-43da-9b5d-29a334683d9f"
      },
      "source": [
        "print(classification_report(y_test.argmax(axis=1),predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      0.53      0.70        15\n",
            "           2       0.70      1.00      0.82        16\n",
            "\n",
            "    accuracy                           0.86        50\n",
            "   macro avg       0.90      0.84      0.84        50\n",
            "weighted avg       0.90      0.86      0.85        50\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "COFwJoplwJPu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "fdfeb1a3-699b-4bb0-fce5-15114306f8ca"
      },
      "source": [
        "print(accuracy_score(y_test.argmax(axis=1),predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1pFyy8ZwMOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BubOw-AwQC5",
        "colab_type": "text"
      },
      "source": [
        "for really large network, we need to save and load our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVdpvMfEwWAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('myfirst.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MvwrYsiwfeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now import this model.\n",
        "# be careful to run the cell saved model again because it will overwrite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POLocYn8xFmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8h16LI4xKwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "a8d540a9-7314-45ac-e19e-7da05c62681e"
      },
      "source": [
        "new_model = load_model('myfisrt.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-7a2941738aaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'myfisrt.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m       \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    111\u001b[0m                   (export_dir,\n\u001b[1;32m    112\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: myfisrt.h5/{saved_model.pbtxt|saved_model.pb}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxRsAblFxgyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}